{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJFPpl1ShKiLJHy13WF+st",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakaleshhubli/ML-Lab-25-26/blob/main/L1_perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single Layer Perceptron for Logic Gates (AND, OR, XOR)\n",
        "\n",
        "This notebook implements a simple perceptron from scratch in Python to learn AND, OR, and XOR gates.\n",
        "\n",
        "- A perceptron is the simplest form of a neural network.\n",
        "- It computes a weighted sum of inputs and passes it through a step activation function.\n",
        "- We will train it using the perceptron learning rule.\n"
      ],
      "metadata": {
        "id": "cqodwLLtJzCn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81V1iJotCT1Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def step_function(x):\n",
        "    return np.where(x >= 0, 1, 0)\n"
      ],
      "metadata": {
        "id": "aQOvop6dCsjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Step Activation Function\n",
        "The perceptron uses a step function:\n",
        "- If weighted sum >= 0 → output = 1\n",
        "- Else → output = 0"
      ],
      "metadata": {
        "id": "_3vQiI2DJ_DX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron_train(X, y, lr=0.1, epochs=10):\n",
        "    w = np.zeros(X.shape[1])\n",
        "    b = 0\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        for i in range(len(X)):\n",
        "            linear_output = np.dot(X[i], w) + b\n",
        "            y_pred = step_function(linear_output)\n",
        "            error = y[i] - y_pred\n",
        "            w += lr * error * X[i]\n",
        "            b += lr * error\n",
        "    return w, b\n"
      ],
      "metadata": {
        "id": "NVBeBpduC4pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Perceptron Training Rule\n",
        "We update weights `w` and bias `b` using:\n",
        "\n",
        "- error = (actual - predicted)\n",
        "- w = w + learning_rate * error * x\n",
        "- b = b + learning_rate * error\n"
      ],
      "metadata": {
        "id": "eEJ-nX_YKKEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron_predict(X, w, b):\n",
        "    return step_function(np.dot(X, w) + b)"
      ],
      "metadata": {
        "id": "6fOB4eTNKfO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data for AND gate\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y_and = np.array([0,0,0,1])\n",
        "\n",
        "w_and, b_and = perceptron_train(X, y_and)\n",
        "print(\"Weights (AND):\", w_and, \"Bias:\", b_and)\n",
        "\n",
        "print(\"Predictions (AND):\", perceptron_predict(X, w_and, b_and))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TqsGNkCC6Ec",
        "outputId": "100e7f36-2878-485b-ef10-b356ffb620c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights (AND): [0.2 0.1] Bias: -0.20000000000000004\n",
            "Predictions (AND): [0 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_or = np.array([0,1,1,1])\n",
        "\n",
        "w_or, b_or = perceptron_train(X, y_or)\n",
        "print(\"Weights (OR):\", w_or, \"Bias:\", b_or)\n",
        "\n",
        "print(\"Predictions (OR):\", perceptron_predict(X, w_or, b_or))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2NHyV75C_VX",
        "outputId": "c955e1e2-8dc2-486a-d08d-b56efe948966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights (OR): [0.1 0.1] Bias: -0.1\n",
            "Predictions (OR): [0 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_xor = np.array([0,1,1,0])\n",
        "\n",
        "w_xor, b_xor = perceptron_train(X, y_xor)\n",
        "print(\"Weights (XOR):\", w_xor, \"Bias:\", b_xor)\n",
        "\n",
        "print(\"Predictions (XOR):\", perceptron_predict(X, w_xor, b_xor))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lml7Rr88Kt9d",
        "outputId": "a672e866-0c21-475f-81bf-1685b04fe6d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights (XOR): [-0.1  0. ] Bias: 0.0\n",
            "Predictions (XOR): [1 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SHDRK7KqKzaW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}